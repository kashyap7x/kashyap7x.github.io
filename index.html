<!DOCTYPE html>
<html>
<head>
<title>Kashyap Chitta | Machine Learning Researcher</title>
<link rel="stylesheet" type="text/css" href="style.css">

<script type="text/javascript" src="js/hidebib.js"></script>

</head>
<body>

<div class="section">
<h1>Kashyap Chitta</h1>
</div>
<hr>

<div class="section">
<table>
  <tr valign="top"> <td style="width: 700px; vertical-align: top;">
  I am a Deep Learning Intern at <a href = "https://www.nvidia.com/en-us/deep-learning-ai/">NVIDIA</a>, Santa Clara working with <a href = "http://www.josemalvarez.net/">Dr. Jose M. Alvarez</a>. I recently graduated with a Master's degree in Computer Vision from CMU, where I was advised by <a href = "http://www.cs.cmu.edu/~hebert/">Prof. Martial Hebert</a>. I am interested in understanding the strengths and weaknesses of machine learning algorithms through uncertainty estimates, so as to adaptively build better datasets for their training.
  <p><br></p>
  <p>
    <a href="javascript:toggleblock('email')">email</a> | <a href="https://github.com/kashyap7x">github</a>  | <a href="https://www.linkedin.com/in/kchitta/">linkedin</a> | <a href="https://twitter.com/kashyap7x">twitter</a> | <a href="https://scholar.google.com/citations?user=vX5i2CcAAAAJ&hl=en">google scholar</a>
  </p>
  <pre xml:space="preserve" id="email" style="font-size: 12px">

firstname DOT lastname AT gmail DOT com
  </pre>
  <script xml:space="preserve" language="JavaScript">
  hideblock('email');
  </script>
  </td>

  <td width="300"><img src="img.jpg" alt="My picture" height=240 align="right"/></td>
    </tr>
  </table>
</div>

<div class="section">
<h2> Publications </h2>
<!--------------------------------------------------------------------------->
<div class="paper" id="chitta2019less">
<img class="paper" title="Less is More: An Exploration of Data Redundancy with Active Dataset Subsampling" src="figures/chitta2019less.png" />
<p> <strong style="color:red">[New]</strong> <b id="papertitle">Less is More: An Exploration of Data Redundancy with Active Dataset Subsampling</b> <br/>
<strong>Kashyap Chitta</strong>, Jose M. Alvarez, Elmar Haussmann, Clement Farabet <br/>
ArXiv e-prints, 2019 <br/>
<a href="https://arxiv.org/pdf/1905.12737.pdf">pdf </a>  &nbsp <a href="javascript:toggleblock('chitta2019lessAbs')">abstract </a>  &nbsp <a href="javascript:toggleblock('chitta2019lessBib')">bibtex </a> </p>
<div class="papermeta" id="chitta2019lessMeta">
<em id="chitta2019lessAbs">Deep Neural Networks (DNNs) often rely on very large datasets for training. Given the large size of such datasets, it is conceivable that they contain certain samples that either do not contribute or negatively impact the DNN's performance. If there is a large number of such samples, subsampling the training dataset in a way that removes them could provide an effective solution to both improve performance and reduce training time. In this paper, we propose an approach called Active Dataset Subsampling (ADS), to identify favorable subsets within a dataset for training using ensemble based uncertainty estimation. When applied to three image classification benchmarks (CIFAR-10, CIFAR-100 and ImageNet) we find that there are low uncertainty subsets, which can be as large as 50% of the full dataset, that negatively impact performance. These subsets are identified and removed with ADS. We demonstrate that datasets obtained using ADS with a lightweight ResNet-18 ensemble remain effective when used to train deeper models like ResNet-101. Our results provide strong empirical evidence that using all the available data for training can hurt performance on large scale vision tasks. </em>
<pre xml:space="preserve" id="chitta2019lessBib">

@inProceedings{chitta2019less,
  title={Less is More: An Exploration of Data Redundancy with Active Dataset Subsampling},
  author = {Kashyap Chitta
  and Jose M. Alvarez
  and Elmar Haussmann
  and Clement Farabet},
  booktitle={ArXiv e-prints},
  year={2019}
}</pre></td>
<script language="javascript" type="text/javascript" xml:space="preserve">
hideblock('chitta2019lessAbs');
hideblock('chitta2019lessBib');
</script>
</div>
</div>
<!--------------------------------------------------------------------------->

<!--------------------------------------------------------------------------->
<div class="paper" id="chitta2018largescale">
<img class="paper" title="Large-Scale Visual Active Learning with Deep Probabilistic Ensembles" src="figures/chitta2018largescale.png" />
<p> <b id="papertitle">Large-Scale Visual Active Learning with Deep Probabilistic Ensembles</b> <br/>
<strong>Kashyap Chitta</strong>, Jose M. Alvarez, Adam Lesnikowski <br/>
ArXiv e-prints, 2018 <br/>
<a href="https://arxiv.org/pdf/1811.03575.pdf">pdf </a>  &nbsp <a href="javascript:toggleblock('chitta2018largescaleAbs')">abstract </a>  &nbsp <a href="javascript:toggleblock('chitta2018largescaleBib')">bibtex </a> </p>
<div class="papermeta" id="chitta2018largescaleMeta">
<em id="chitta2018largescaleAbs">Annotating the right data for training deep neural networks is an important challenge. Active learning using uncertainty estimates from Bayesian Neural Networks (BNNs) could provide an effective solution to this. Despite being theoretically principled, BNNs require approximations to be applied to large-scale problems, where both performance and uncertainty estimation are crucial. In this paper, we introduce Deep Probabilistic Ensembles (DPEs), a scalable technique that uses a regularized ensemble to approximate a deep BNN. We conduct a series of large-scale visual active learning experiments to evaluate DPEs on classification with the CIFAR-10, CIFAR-100 and ImageNet datasets, and semantic segmentation with the BDD100k dataset. Our models require significantly less training data to achieve competitive performances, and steadily improve upon strong active learning baselines as the annotation budget is increased. </em>
<pre xml:space="preserve" id="chitta2018largescaleBib">

@inProceedings{chitta2018largescale,
  title={Large-Scale Visual Active Learning with Deep Probabilistic Ensembles},
  author = {Kashyap Chitta
  and Jose M. Alvarez
  and Adam Lesnikowski},
  booktitle={ArXiv e-prints},
  year={2018}
}</pre></td>
<script language="javascript" type="text/javascript" xml:space="preserve">
hideblock('chitta2018largescaleAbs');
hideblock('chitta2018largescaleBib');
</script>
</div>
</div>
<!--------------------------------------------------------------------------->

<!--------------------------------------------------------------------------->
<div class="paper" id="chitta2018adaptive">
<img class="paper" title="Adaptive Semantic Segmentation with a Strategic Curriculum of Proxy Labels" src="figures/chitta2018adaptive.png" />
<p> <b id="papertitle">Adaptive Semantic Segmentation with a Strategic Curriculum of Proxy Labels</b> <br/>
<strong>Kashyap Chitta</strong>, Jianwei Feng, Martial Hebert <br/>
ArXiv e-prints, 2018 <br/>
<a href="https://arxiv.org/pdf/1811.03542.pdf">pdf </a>  &nbsp <a href="javascript:toggleblock('chitta2018adaptiveAbs')">abstract </a>  &nbsp <a href="javascript:toggleblock('chitta2018adaptiveBib')">bibtex </a>  &nbsp <a href="https://github.com/kashyap7x/Domain-Adapatation">code </a> </p>
<div class="papermeta" id="chitta2018adaptiveMeta">
<em id="chitta2018adaptiveAbs">Training deep networks for semantic segmentation requires annotation of large amounts of data, which can be time-consuming and expensive. Unfortunately, these trained networks still generalize poorly when tested in domains not consistent with the training data. In this paper, we show that by carefully presenting a mixture of labeled source domain and proxy-labeled target domain data to a network, we can achieve state-of-the-art unsupervised domain adaptation results. With our design, the network progressively learns features specific to the target domain using annotation from only the source domain. We generate proxy labels for the target domain using the network's own predictions. Our architecture then allows selective mining of easy samples from this set of proxy labels, and hard samples from the annotated source domain. We conduct a series of experiments with the GTA5, Cityscapes and BDD100k datasets on synthetic-to-real domain adaptation and geographic domain adaptation, showing the advantages of our method over baselines and existing approaches.</em>
<pre xml:space="preserve" id="chitta2018adaptiveBib">

@inProceedings{chitta2018adaptive,
  title={Adaptive Semantic Segmentation with a Strategic Curriculum of Proxy Labels},
  author = {Kashyap Chitta
  and Jianwei Feng
  and Martial Hebert},
  booktitle={ArXiv e-prints},
  year={2018}
}</pre></td>
<script language="javascript" type="text/javascript" xml:space="preserve">
hideblock('chitta2018adaptiveAbs');
hideblock('chitta2018adaptiveBib');
</script>
</div>
</div>
<!--------------------------------------------------------------------------->

<!--------------------------------------------------------------------------->
<div class="paper" id="chitta2018deep">
<img class="paper" title="Deep Probabilistic Ensembles: Approximate Variational Inference through KL Regularization" src="figures/chitta2018deep.png" />
<p><b id="papertitle">Deep Probabilistic Ensembles: Approximate Variational Inference through KL Regularization</b> <br/>
<strong>Kashyap Chitta</strong>, Jose M. Alvarez, Adam Lesnikowski <br/>
Workshop on Bayesian Deep Learning (BDL), NeurIPS, 2018 <br/>
<a href="https://arxiv.org/pdf/1811.02640.pdf">pdf </a>  &nbsp <a href="javascript:toggleblock('chitta2018deepAbs')">abstract </a>  &nbsp <a href="javascript:toggleblock('chitta2018deepBib')">bibtex </a> </p>
<div class="papermeta" id="chitta2018deepMeta">
<em id="chitta2018deepAbs"> In this paper, we introduce Deep Probabilistic Ensembles (DPEs), a scalable technique that uses a regularized ensemble to approximate a deep Bayesian Neural Network (BNN). We do so by incorporating a KL divergence penalty term into the training objective of an ensemble, derived from the evidence lower bound used in variational inference. We evaluate the uncertainty estimates obtained from our models for active learning on visual classification. Our approach steadily improves upon active learning baselines as the annotation budget is increased.</em>
<pre xml:space="preserve" id="chitta2018deepBib">

@inProceedings{chitta2018deep,
  title={Deep Probabilistic Ensembles: Approximate Variational Inference through KL Regularization},
  author = {Kashyap Chitta
  and Jose M. Alvarez
  and Adam Lesnikowski},
  booktitle={Workshop on Bayesian Deep Learning (BDL), Conference on Neural Information Processing Systems (NeurIPS)},
  year={2018}
}</pre></td>
<script language="javascript" type="text/javascript" xml:space="preserve">
hideblock('chitta2018deepAbs');
hideblock('chitta2018deepBib');
</script>
</div>
</div>
<!--------------------------------------------------------------------------->

<!--------------------------------------------------------------------------->
<div class="paper" id="chitta2018targeted">
<img class="paper" title="Targeted Kernel Networks: Faster Convolutions with Attentive Regularization" src="figures/chitta2018targeted.png" />
<p><b id="papertitle">Targeted Kernel Networks: Faster Convolutions with Attentive Regularization</b> <br/>
<strong>Kashyap Chitta</strong><br/>
Workshop on Compact and Efficient Feature Representation and Learning in Computer Vision (CEFRL), ECCV, 2018 <br/>
<a href="https://arxiv.org/pdf/1806.00523.pdf">pdf </a>  &nbsp <a href="javascript:toggleblock('chitta2018targetedAbs')">abstract </a>  &nbsp <a href="javascript:toggleblock('chitta2018targetedBib')">bibtex </a>  &nbsp <a href="https://github.com/kashyap7x/Attentive-Regularization">code </a> </p>
<div class="papermeta" id="chitta2018targetedMeta">
<em id="chitta2018targetedAbs"> We propose Attentive Regularization (AR), a method to constrain the activation maps of kernels in Convolutional Neural Networks (CNNs) to specific regions of interest (ROIs). Each kernel learns a location of specialization along with its weights through standard backpropagation. A differentiable attention mechanism requiring no additional supervision is used to optimize the ROIs. Traditional CNNs of different types and structures can be modified with this idea into equivalent Targeted Kernel Networks (TKNs), while keeping the network size nearly identical. By restricting kernel ROIs, we reduce the number of sliding convolutional operations performed throughout the network in its forward pass, speeding up both training and inference. We evaluate our proposed architecture on both synthetic and natural tasks across multiple domains. TKNs obtain significant improvements over baselines, requiring less computation (around an order of magnitude) while achieving superior performance.</em>
<pre xml:space="preserve" id="chitta2018targetedBib">

@inProceedings{chitta2018targeted,
  title={Targeted Kernel Networks: Faster Convolutions with Attentive Regularization},
  author = {Kashyap Chitta},
  booktitle={Workshop on Compact and Efficient Feature Representation and Learning in Computer Vision (CEFRL), European Conference on Computer Vision (ECCV)},
  year={2018}
}</pre></td>
<script language="javascript" type="text/javascript" xml:space="preserve">
hideblock('chitta2018targetedAbs');
hideblock('chitta2018targetedBib');
</script>
</div>
</div>
<!--------------------------------------------------------------------------->

<!--------------------------------------------------------------------------->
<div class="paper" id="patel2018learning">
<img class="paper" title="Learning Sampling Policies for Domain Adaptation" src="figures/patel2018learning.png" />
<p><b id="papertitle">Learning Sampling Policies for Domain Adaptation</b> <br/>
Yash Patel*, <strong>Kashyap Chitta</strong>*, Bhavan Jasani* <br/>
ArXiv e-prints, 2018 <br/>
<a href="https://arxiv.org/pdf/1805.07641.pdf">pdf </a>  &nbsp <a href="javascript:toggleblock('patel2018learningAbs')">abstract </a>  &nbsp <a href="javascript:toggleblock('patel2018learningBib')">bibtex </a>  &nbsp <a href="https://github.com/yash0307/LearningSamplingPolicies">code </a> </p>
<div class="papermeta" id="patel2018learningMeta">
<em id="patel2018learningAbs">We address the problem of semi-supervised domain adaptation of classification algorithms through deep Q-learning. The core idea is to consider the predictions of a source domain network on target domain data as noisy labels, and learn a policy to sample from this data so as to maximize classification accuracy on a small annotated reward partition of the target domain. Our experiments show that learned sampling policies construct labeled sets that improve accuracies of visual classifiers over baselines.</em>
<pre xml:space="preserve" id="patel2018learningBib">

@inProceedings{patel2018learning,
  title={Learning Sampling Policies for Domain Adaptation},
  author = {Yash Patel
  and Kashyap Chitta
  and Bhavan Jasani},
  booktitle={ArXiv e-prints},
  year={2018}
}</pre></td>
<script language="javascript" type="text/javascript" xml:space="preserve">
hideblock('patel2018learningAbs');
hideblock('patel2018learningBib');
</script>
</div>
</div>
<!--------------------------------------------------------------------------->

<!--------------------------------------------------------------------------->
<div class="paper" id="chitta2016reduced">
<img class="paper" title="A Reduced Region of Interest Based Approach for Facial Expression Recognition from Static Images" src="figures/chitta2016reduced.png" />
<p><b id="papertitle">A Reduced Region of Interest Based Approach for Facial Expression Recognition from Static Images</b> <br/>
<strong>Kashyap Chitta</strong>, Neeraj N. Sajjan <br/>
IEEE TENCON, 2016 <br/>
<a href="https://ieeexplore.ieee.org/document/7848553">pdf </a>  &nbsp <a href="javascript:toggleblock('chitta2016reducedAbs')">abstract </a>  &nbsp <a href="javascript:toggleblock('chitta2016reducedBib')">bibtex </a> </p>
<div class="papermeta" id="chitta2016reducedMeta">
<em id="chitta2016reducedAbs">The general approach to facial expression recognition involves three stages: face acquisition, feature extraction and expression recognition. A series of steps are used during feature extraction, and the robustness of a recognition model depends on the ability to handle exceptions over all these steps. This paper details experiments conducted to classify images by facial expression using reduced regions of interest and discriminative salient patches on the face, while minimizing the number of steps required for their localization. The performance of various feature descriptors is analyzed and a model for expression recognition for which experiments on the JAFFE database show effectiveness is proposed.</em>
<pre xml:space="preserve" id="chitta2016reducedBib">

@inProceedings{chitta2016reduced,
  title={A Reduced Region of Interest Based Approach for Facial Expression Recognition from Static Images},
  author = {Kashyap Chitta
  and Neeraj N. Sajjan},
  booktitle={IEEE Region-10 Conference (TENCON)},
  year={2016}
}</pre></td>
<script language="javascript" type="text/javascript" xml:space="preserve">
hideblock('chitta2016reducedAbs');
hideblock('chitta2016reducedBib');
</script>
</div>
</div>
<!--------------------------------------------------------------------------->

<!--------------------------------------------------------------------------->
<!--- TEMPLATE
<div class="paper" id="paperId">
  <img class="paper" title="X" src="images/X.png" />
  <p><b id="papertitle">Title</b> <br/>
  <strong>Kashyap Chitta</strong>, Author2, Author3 <br />
  Conference, 2019<br />
  <a href="link">pdf</a>  &nbsp <a href="page">project page</a>  &nbsp <a href="javascript:toggleblock('paperIdAbs')">abstract</a> &nbsp <a href="javascript:toggleblock('paperIdBib')">bibtex</a>  &nbsp <a href="codelink">code</a> </p>

  <div class="papermeta" id="paperIdMeta">
  <em id="paperIdAbs">ABSTRACT</em></p>
  <pre xml:space="preserve" id="paperIdBib" style="font-size: 12px">
@inProceedings{
BIBTEX
}</pre></td>
  <script language="javascript" type="text/javascript" xml:space="preserve">
     hideblock('paperIdAbs');
     hideblock('paperIdBib');
  </script>
  </div>
</div>
-->
<!--------------------------------------------------------------------------->

</body>
</html>
