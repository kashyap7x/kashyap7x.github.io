
    <!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha512-SnH5WK+bZxgPHs44uWIX+LLJAJ9/2PkPKZ5QiAj6Ta86w+fsb2TkcmfRyVX3pBnMFcV7oQPJkl9QevSCWr3W6A==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  <title>Kashyap Chitta | AI Researcher</title>
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
</head>

<body>
    <div class="container">
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="margin-bottom: 1em;">
            <h3 class="display-4" style="text-align: center;"><span style="font-weight: bold;">Kashyap</span> Chitta</h3>
            </div>
            <br>
            <div class="col-md-8" style="">
                
                <p>
                    I am a Postdoctoral Researcher at the <a href="https://research.nvidia.com/labs/avg/" target="_blank">NVIDIA Autonomous Vehicle Research Group</a> working from Tübingen, Germany. My research focuses on simulation-based training and evaluation of Physical AI systems. Representative papers are <span style="background-color:#ffffd0">highlighted</span> below.
                </p>
                <p>
                    <span style="font-weight: bold;">Bio:</span>
                    Kashyap did a bachelor's degree in electronics at the <a href="https://www.rvce.edu.in/" target="_blank">RV College of Engineering</a>, India. He then moved to the US in 2017 to obtain his Master's degree in computer vision from <a href="https://www.ri.cmu.edu/" target="_blank">Carnegie Mellon University</a>, where he was advised by <a href = "http://www.cs.cmu.edu/~hebert/" target="_blank">Prof. Martial Hebert</a>. During this time, he was also an intern at the <a href = "https://research.nvidia.com/labs/av-applied-research/" target="_blank">NVIDIA Autonomous Vehicles Applied Research Group</a> working with <a href = "https://alvarezlopezjosem.github.io/" target="_blank">Dr. Jose M. Alvarez</a>. From 2019, he was a PhD student in the <a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/autonomous-vision/home/" target="_blank">Autonomous Vision Group</a> at the University of Tübingen, Germany, supervised by <a href="http://cvlibs.net/" target="_blank">Prof. Andreas Geiger</a>. He was selected for the <a href="https://iccv2023.thecvf.com/doctoral.consortium-353000-2-30.php" target="_blank">doctoral consortium</a> at ICCV 2023, as a 2023 <a href="https://sites.google.com/view/rsspioneers2023/participants" target="_blank">RSS pioneer</a>, and an outstanding reviewer for <a href="https://cvpr2023.thecvf.com/Conferences/2023/OutstandingReviewers" target="_blank">CVPR</a>, <a href="https://twitter.com/kashyap7x/status/1712169445349560517" target="_blank">ICCV</a>, <a href="https://eccv.ecva.net/Conferences/2024/Reviewers" target="_blank">ECCV</a>, and <a href="https://neurips.cc/Conferences/2023/ProgramCommittee#top-reivewers" target="_blank">NeurIPS</a>. He has also won multiple autonomous driving challenge awards <a href="https://opendrivelab.com/challenge2023/#nuplan_planning" target="_blank">[nuPlan 2023]</a> <a href="https://leaderboard.carla.org/challenge/#previous-carla-ad-challenges" target="_blank">[CARLA 2020, 2021, 2022, 2023, 2024]</a> <a href="https://waymo.com/open/challenges/" target="_blank">[Waymo 2025]</a> <a href="https://realadsim.github.io/2025/#challenge" target="_blank">[HUGSIM 2025]</a>.
                </p>
                <p>
                    <a href="https://kashyap7x.github.io/assets/pdf/kchitta_cv.pdf" target="_blank" style="margin-right: 15px"><i class="fa fa-address-card fa-lg"></i> CV</a>
                    <a href="mailto:kchitta@nvidia.com" style="margin-right: 15px"><i class="far fa-envelope-open fa-lg"></i> Mail</a>
                    <a href="https://scholar.google.com/citations?user=vX5i2CcAAAAJ&hl=en" target="_blank" style="margin-right: 15px"><i class="fa-solid fa-graduation-cap"></i> Scholar</a>
                    <a href="https://kashyap7x.substack.com" target="_blank" style="margin-right: 15px"><i class="fa-solid fa-feather fa-lg"></i> Substack</a>
                    <a href="https://www.linkedin.com/in/kchitta" target="_blank" style="margin-right: 15px"><i class="fab fa-linkedin fa-lg"></i> Linkedin</a>
                    <a href="https://github.com/kashyap7x" target="_blank" style="margin-right: 15px"><i class="fab fa-github fa-lg"></i> GitHub</a>
                    <a href="https://www.youtube.com/channel/UC_rpEkxE-pUAV8v0wjdtg5w" target="_blank" style="margin-right: 15px"><i class="fab fa-youtube fa-lg"></i> YouTube</a>
                </p>
    
            </div>
            <div class="col-md-4" style="">
                <img src="assets/img/profile.jpg" class="img-thumbnail" alt="Profile picture">
            </div>
        </div>
        <div class="row" style="margin-top: 1em;">
            <div class="col-sm-12" style="">
                <h4>Publications</h4>
                <hr>
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Yang2025NEURIPS.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2506.09981" target="_blank">ReSim: Reliable World Simulation for Autonomous Driving</a> <span style="color: red;">(Spotlight)</span><br><a href="https://www.linkedin.com/in/jiazhi-yang-a07805208/" target="_blank">Jiazhi Yang</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://github.com/Little-Podi" target="_blank">Shenyuan Gao</a>, <a href="https://long.ooo/" target="_blank">Long Chen</a>, <a href="https://meteorcollector.github.io/" target="_blank">Yuqian Shao</a>, <a href="https://jiaxiaosong1002.github.io/" target="_blank">Xiaosong Jia</a>, <a href="https://lihongyang.info/" target="_blank">Hongyang Li</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a>, <a href="https://xyue.io/" target="_blank">Xiangyu Yue</a>, <a href="https://www.linkedin.com/in/li-chen-30b256167/" target="_blank">Li Chen</a> <br><span style="font-style: italic;">Advances in Neural Information Processing Systems (NeurIPS)</span>, 2025 <br><a href="https://arxiv.org/abs/2506.09981" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2506.09981" target="_blank">Paper</a> / <a href="https://github.com/OpenDriveLab/ReSim" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseYang2025NEURIPS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseYang2025NEURIPS"><div class="card card-body"><pre><code>@inproceedings{Yang2025NEURIPS, 
	author = {Jiazhi Yang and Kashyap Chitta and Shenyuan Gao and Long Chen and Yuqian Shao and Xiaosong Jia and Hongyang Li and Andreas Geiger and Xiangyu Yue and Li Chen}, 
	title = {ReSim: Reliable World Simulation for Autonomous Driving}, 
	booktitle = {Advances in Neural Information Processing Systems (NeurIPS)}, 
	year = {2025}, 
}</pre></code></div></div> </div> </div> </div><div style="background-color: #ffffd0; margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Cao2025CORL.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2506.04218" target="_blank">Pseudo-Simulation for Autonomous Driving</a> <br><a href="https://vveicao.github.io/" target="_blank">Wei Cao</a>*, <a href="https://mh0797.github.io/" target="_blank">Marcel Hallgarten</a>*, <a href="https://www.linkedin.com/in/sephy-li/" target="_blank">Tianyu Li</a>*, <a href="https://danieldauner.github.io/" target="_blank">Daniel Dauner</a>, <a href="https://alfredgu001324.github.io/" target="_blank">Xunjiang Gu</a>, <a href="https://scholar.google.com/citations?user=35xHlDUAAAAJ" target="_blank">Caojun Wang</a>, <a href="https://www.linkedin.com/in/yakov-miron-0826121b/" target="_blank">Yakov Miron</a>, <a href="http://aiellom.it/" target="_blank">Marco Aiello</a>, <a href="https://lihongyang.info/" target="_blank">Hongyang Li</a>, <a href="https://www.gilitschenski.org/igor/" target="_blank">Igor Gilitschenski</a>, <a href="https://www.borisivanovic.com/" target="_blank">Boris Ivanovic</a>, <a href="https://web.stanford.edu/~pavone/" target="_blank">Marco Pavone</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a>, <span style="font-weight: bold";>Kashyap Chitta</span> <br><span style="font-style: italic;">Conference on Robot Learning (CoRL)</span>, 2025 <br><a href="https://arxiv.org/abs/2506.04218" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2506.04218.pdf" target="_blank">Paper</a> / <a href="https://vveicao.github.io/projects/NavsimV2/Cao2025_supp.pdf" target="_blank">Supplementary</a> / <a href="https://github.com/autonomousvision/navsim" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseCao2025CORL" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseCao2025CORL"><div class="card card-body"><pre><code>@inproceedings{Cao2025CORL, 
	author = {Wei Cao and Marcel Hallgarten and Tianyu Li and Daniel Dauner and Xunjiang Gu and Caojun Wang and Yakov Miron and Marco Aiello and Hongyang Li and Igor Gilitschenski and Boris Ivanovic and Marco Pavone and Andreas Geiger and Kashyap Chitta}, 
	title = {Pseudo-Simulation for Autonomous Driving}, 
	booktitle = {Conference on Robot Learning (CoRL)}, 
	year = {2025}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Jaeger2025CORL.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2504.17838" target="_blank">CaRL: Learning Scalable Planning Policies with Simple Rewards</a> <br><a href="https://kait0.github.io/" target="_blank">Bernhard Jaeger</a>, <a href="https://danieldauner.github.io/" target="_blank">Daniel Dauner</a>, <a href="https://www.linkedin.com/in/jens-beißwenger-a82430258" target="_blank">Jens Beißwenger</a>, <a href="https://www.linkedin.com/in/simon-gerstenecker/" target="_blank">Simon Gerstenecker</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Conference on Robot Learning (CoRL)</span>, 2025 <br><a href="https://arxiv.org/abs/2504.17838" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2504.17838.pdf" target="_blank">Paper</a> / <a href="https://www.youtube.com/watch?v=_godUKkICec" target="_blank">Video</a> / <a href="https://github.com/autonomousvision/carl" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseJaeger2025CORL" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseJaeger2025CORL"><div class="card card-body"><pre><code>@inproceedings{Jaeger2025CORL, 
	author = {Bernhard Jaeger and Daniel Dauner and Jens Beißwenger and Simon Gerstenecker and Kashyap Chitta and Andreas Geiger}, 
	title = {CaRL: Learning Scalable Planning Policies with Simple Rewards}, 
	booktitle = {Conference on Robot Learning (CoRL)}, 
	year = {2025}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Gao2024NEURIPS.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2405.17398" target="_blank">Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability</a> <br><a href="https://github.com/Little-Podi" target="_blank">Shenyuan Gao</a>, <a href="https://www.linkedin.com/in/jiazhi-yang-a07805208/" target="_blank">Jiazhi Yang</a>, <a href="https://www.linkedin.com/in/li-chen-30b256167/" target="_blank">Li Chen</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://github.com/gihharwtw" target="_blank">Yihang Qiu</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a>, <a href="https://eejzhang.people.ust.hk/" target="_blank">Jun Zhang</a>, <a href="https://lihongyang.info/" target="_blank">Hongyang Li</a> <br><span style="font-style: italic;">Advances in Neural Information Processing Systems (NeurIPS)</span>, 2024 <br><a href="https://arxiv.org/abs/2405.17398" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2405.17398" target="_blank">Paper</a> / <a href="https://www.youtube.com/watch?v=2BGxnJLD_qw" target="_blank">Video</a> / <a href="https://github.com/OpenDriveLab/Vista" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseGao2024NEURIPS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseGao2024NEURIPS"><div class="card card-body"><pre><code>@inproceedings{Gao2024NEURIPS, 
	author = {Shenyuan Gao and Jiazhi Yang and Li Chen and Kashyap Chitta and Yihang Qiu and Andreas Geiger and Jun Zhang and Hongyang Li}, 
	title = {Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability}, 
	booktitle = {Advances in Neural Information Processing Systems (NeurIPS)}, 
	year = {2024}, 
}</pre></code></div></div> </div> </div> </div><div style="background-color: #ffffd0; margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Dauner2024NEURIPS.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2406.15349" target="_blank">NAVSIM: Data-Driven Non-Reactive Autonomous Vehicle Simulation and Benchmarking</a> <br><a href="https://danieldauner.github.io/" target="_blank">Daniel Dauner</a>, <a href="https://mh0797.github.io/" target="_blank">Marcel Hallgarten</a>, <a href="https://www.linkedin.com/in/sephy-li/" target="_blank">Tianyu Li</a>, <a href="https://research.nvidia.com/person/xinshuo-weng" target="_blank">Xinshuo Weng</a>, <a href="https://mczhi.github.io/" target="_blank">Zhiyu Huang</a>, <a href="https://scholar.google.com/citations?user=oPiZSVYAAAAJ&hl=zh-CN" target="_blank">Zetong Yang</a>, <a href="https://lihongyang.info/" target="_blank">Hongyang Li</a>, <a href="https://www.gilitschenski.org/igor/" target="_blank">Igor Gilitschenski</a>, <a href="https://www.borisivanovic.com/" target="_blank">Boris Ivanovic</a>, <a href="https://web.stanford.edu/~pavone/" target="_blank">Marco Pavone</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a>, <span style="font-weight: bold";>Kashyap Chitta</span> <br><span style="font-style: italic;">Advances in Neural Information Processing Systems (NeurIPS)</span>, 2024 <br><a href="https://arxiv.org/abs/2406.15349" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2406.15349" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Dauner2024NEURIPS_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://youtu.be/Qe76HRmPDe0?si=VQoYLNNzr2zYqIiX" target="_blank">Video</a> / <a href="https://github.com/autonomousvision/navsim" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseDauner2024NEURIPS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseDauner2024NEURIPS"><div class="card card-body"><pre><code>@inproceedings{Dauner2024NEURIPS, 
	author = {Daniel Dauner and Marcel Hallgarten and Tianyu Li and Xinshuo Weng and Zhiyu Huang and Zetong Yang and Hongyang Li and Igor Gilitschenski and Boris Ivanovic and Marco Pavone and Andreas Geiger and Kashyap Chitta}, 
	title = {NAVSIM: Data-Driven Non-Reactive Autonomous Vehicle Simulation and Benchmarking}, 
	booktitle = {Advances in Neural Information Processing Systems (NeurIPS)}, 
	year = {2024}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Chen2024PAMI.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2306.16927" target="_blank">End-to-end Autonomous Driving: Challenges and Frontiers</a> <br><a href="https://www.linkedin.com/in/li-chen-30b256167/" target="_blank">Li Chen</a>, <a href="https://penghao-wu.github.io/" target="_blank">Penghao Wu</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://kait0.github.io/" target="_blank">Bernhard Jaeger</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a>, <a href="https://lihongyang.info/" target="_blank">Hongyang Li</a> <br><span style="font-style: italic;">Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</span>, 2024 <br><a href="https://arxiv.org/abs/2306.16927" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2306.16927" target="_blank">Paper</a> / <a href="https://github.com/OpenDriveLab/End-to-end-Autonomous-Driving" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseChen2024PAMI" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseChen2024PAMI"><div class="card card-body"><pre><code>@article{Chen2024PAMI, 
	author = {Li Chen and Penghao Wu and Kashyap Chitta and Bernhard Jaeger and Andreas Geiger and Hongyang Li}, 
	title = {End-to-end Autonomous Driving: Challenges and Frontiers}, 
	booktitle = {Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)}, 
	year = {2024}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Sima2024ECCV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2312.14150" target="_blank">DriveLM: Driving with Graph Visual Question Answering</a> <span style="color: red;">(Oral)</span><br><a href="https://github.com/ChonghaoSima" target="_blank">Chonghao Sima</a>*, <a href="https://www.katrinrenz.de/" target="_blank">Katrin Renz</a>*, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.linkedin.com/in/li-chen-30b256167/" target="_blank">Li Chen</a>, <a href="https://github.com/jjxjiaxue" target="_blank">Hanxue Zhang</a>, <a href="https://github.com/ChengenXie" target="_blank">Chengen Xie</a>, <a href="https://www.linkedin.com/in/jens-beißwenger-a82430258" target="_blank">Jens Beißwenger</a>, <a href="http://luoping.me/" target="_blank">Ping Luo</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a>, <a href="https://lihongyang.info/" target="_blank">Hongyang Li</a> <br><span style="font-style: italic;">European Conference on Computer Vision (ECCV)</span>, 2024 <br><a href="https://arxiv.org/abs/2312.14150" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2312.14150" target="_blank">Paper</a> / <a href="https://github.com/OpenDriveLab/DriveLM" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseSima2024ECCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseSima2024ECCV"><div class="card card-body"><pre><code>@inproceedings{Sima2024ECCV, 
	author = {Chonghao Sima and Katrin Renz and Kashyap Chitta and Li Chen and Hanxue Zhang and Chengen Xie and Jens Beißwenger and Ping Luo and Andreas Geiger and Hongyang Li}, 
	title = {DriveLM: Driving with Graph Visual Question Answering}, 
	booktitle = {European Conference on Computer Vision (ECCV)}, 
	year = {2024}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Chitta2024ECCV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2403.17933" target="_blank">SLEDGE: Synthesizing Driving Environments with Generative Models and Rule-Based Traffic</a> <br><span style="font-weight: bold";>Kashyap Chitta</span>*, <a href="https://danieldauner.github.io/" target="_blank">Daniel Dauner</a>*, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">European Conference on Computer Vision (ECCV)</span>, 2024 <br><a href="https://arxiv.org/abs/2403.17933" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2403.17933" target="_blank">Paper</a> / <a href="https://danieldauner.github.io/assets/pdf/Chitta2024ARXIV_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://youtu.be/el4h1eaYsYs?si=uiopUJIdhW9MyRT5" target="_blank">Video</a> / <a href="https://github.com/autonomousvision/sledge" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseChitta2024ECCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseChitta2024ECCV"><div class="card card-body"><pre><code>@inproceedings{Chitta2024ECCV, 
	author = {Kashyap Chitta and Daniel Dauner and Andreas Geiger}, 
	title = {SLEDGE: Synthesizing Driving Environments with Generative Models and Rule-Based Traffic}, 
	booktitle = {European Conference on Computer Vision (ECCV)}, 
	year = {2024}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Yang2024CVPR.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2403.09630" target="_blank">Generalized Predictive Model for Autonomous Driving</a> <span style="color: red;">(Highlight)</span><br><a href="https://www.linkedin.com/in/jiazhi-yang-a07805208/" target="_blank">Jiazhi Yang</a>*, <a href="https://github.com/Little-Podi" target="_blank">Shenyuan Gao</a>*, <a href="https://github.com/gihharwtw" target="_blank">Yihang Qiu</a>*, <a href="https://www.linkedin.com/in/li-chen-30b256167/" target="_blank">Li Chen</a>, <a href="https://www.linkedin.com/in/sephy-li/" target="_blank">Tianyu Li</a>, <a href="https://www.linkedin.com/in/bo-dai-33673672/" target="_blank">Bo Dai</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://penghao-wu.github.io/" target="_blank">Penghao Wu</a>, <a href="https://scholar.google.com/citations?user=kYrUfMoAAAAJ" target="_blank">Jia Zeng</a>, <a href="http://luoping.me/" target="_blank">Ping Luo</a>, <a href="https://eejzhang.people.ust.hk/" target="_blank">Jun Zhang</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a>, <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ" target="_blank">Yu Qiao</a>, <a href="https://lihongyang.info/" target="_blank">Hongyang Li</a> <br><span style="font-style: italic;">Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2024 <br><a href="https://arxiv.org/abs/2403.09630" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2403.09630.pdf" target="_blank">Paper</a> / <a href="https://github.com/OpenDriveLab/DriveAGI" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseYang2024CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseYang2024CVPR"><div class="card card-body"><pre><code>@inproceedings{Yang2024CVPR, 
	author = {Jiazhi Yang and Shenyuan Gao and Yihang Qiu and Li Chen and Tianyu Li and Bo Dai and Kashyap Chitta and Penghao Wu and Jia Zeng and Ping Luo and Jun Zhang and Andreas Geiger and Yu Qiao and Hongyang Li}, 
	title = {Generalized Predictive Model for Autonomous Driving}, 
	booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)}, 
	year = {2024}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Dauner2023CORL.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2306.07962" target="_blank">Parting with Misconceptions about Learning-based Vehicle Motion Planning</a> <span style="color: red;">(Winner, 2023 nuPlan Challenge)</span><br><a href="https://danieldauner.github.io/" target="_blank">Daniel Dauner</a>, <a href="https://mh0797.github.io/" target="_blank">Marcel Hallgarten</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a>, <span style="font-weight: bold";>Kashyap Chitta</span> <br><span style="font-style: italic;">Conference on Robot Learning (CoRL)</span>, 2023 <br><a href="https://arxiv.org/abs/2306.07962" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2306.07962.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Dauner2023CORL_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://www.youtube.com/watch?v=oIOYQAR5P4w" target="_blank">Video</a> / <a href="assets/pdf/posters/Dauner2023CORL.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/tuplan_garage" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseDauner2023CORL" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseDauner2023CORL"><div class="card card-body"><pre><code>@inproceedings{Dauner2023CORL, 
	author = {Daniel Dauner and Marcel Hallgarten and Andreas Geiger and Kashyap Chitta}, 
	title = {Parting with Misconceptions about Learning-based Vehicle Motion Planning}, 
	booktitle = {Conference on Robot Learning (CoRL)}, 
	year = {2023}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Jaeger2023ICCV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2306.07957" target="_blank">Hidden Biases of End-to-End Driving Models</a> <span style="color: red;">(Winner, 2022 CARLA Challenge Map Track)</span><br><a href="https://kait0.github.io/" target="_blank">Bernhard Jaeger</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">International Conference on Computer Vision (ICCV)</span>, 2023 <br><a href="https://arxiv.org/abs/2306.07957" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2306.07957.pdf" target="_blank">Paper</a> / <a href="https://youtu.be/XbWmGwggcuQ" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Jaeger2023ICCV_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/carla_garage" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseJaeger2023ICCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseJaeger2023ICCV"><div class="card card-body"><pre><code>@inproceedings{Jaeger2023ICCV, 
	author = {Bernhard Jaeger and Kashyap Chitta and Andreas Geiger}, 
	title = {Hidden Biases of End-to-End Driving Models}, 
	booktitle = {International Conference on Computer Vision (ICCV)}, 
	year = {2023}, 
}</pre></code></div></div> </div> </div> </div><div style="background-color: #ffffd0; margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Chitta2023PAMI.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2205.15997" target="_blank">TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving</a> <span style="color: red;">(Runner Up, 2021 CARLA Challenge)</span><br><span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>, <a href="https://kait0.github.io/" target="_blank">Bernhard Jaeger</a>, <a href="https://niujinshuchong.github.io/" target="_blank">Zehao Yu</a>, <a href="https://www.katrinrenz.de/" target="_blank">Katrin Renz</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</span>, 2023 <br><a href="https://arxiv.org/abs/2205.15997" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2205.15997.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Chitta2022PAMI_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://www.youtube.com/watch?v=-GMhYcxOiEU" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Chitta2022PAMI_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/transfuser" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseChitta2023PAMI" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseChitta2023PAMI"><div class="card card-body"><pre><code>@article{Chitta2023PAMI, 
	author = {Kashyap Chitta and Aditya Prakash and Bernhard Jaeger and Zehao Yu and Katrin Renz and Andreas Geiger}, 
	title = {TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving}, 
	booktitle = {Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)}, 
	year = {2023}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Renz2022CORL.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://www.katrinrenz.de/plant/" target="_blank">PlanT: Explainable Planning Transformers via Object-Level Representations</a> <br><a href="https://www.katrinrenz.de/" target="_blank">Katrin Renz</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://merceaotniel.github.io/" target="_blank">Otniel-Bogdan Mercea</a>, <a href="https://www.eml-unitue.de/people/almut-sophia-koepke" target="_blank">Sophia Koepke</a>, <a href="https://www.eml-unitue.de/people/zeynep-akata" target="_blank">Zeynep Akata</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Conference on Robot Learning (CoRL)</span>, 2022 <br><a href="https://www.katrinrenz.de/plant/" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2210.14222.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Renz2022CORL_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://youtu.be/sbnbrLKO9c8" target="_blank">Video</a> / <a href="assets/pdf/posters/Renz2022CORL.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/plant" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseRenz2022CORL" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseRenz2022CORL"><div class="card card-body"><pre><code>@inproceedings{Renz2022CORL, 
	author = {Katrin Renz and Kashyap Chitta and Otniel-Bogdan Mercea and Sophia Koepke and Zeynep Akata and Andreas Geiger}, 
	title = {PlanT: Explainable Planning Transformers via Object-Level Representations}, 
	booktitle = {Conference on Robot Learning (CoRL)}, 
	year = {2022}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Hanselmann2022ECCV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://lasnik.github.io/king/" target="_blank">KING: Generating Safety-Critical Driving Scenarios for Robust Imitation via Kinematics Gradients</a> <span style="color: red;">(Oral)</span><br><a href="https://lasnik.github.io/" target="_blank">Niklas Hanselmann</a>, <a href="https://www.katrinrenz.de/" target="_blank">Katrin Renz</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://apratimbhattacharyya18.github.io/" target="_blank">Apratim Bhattacharyya</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">European Conference on Computer Vision (ECCV)</span>, 2022 <br><a href="https://lasnik.github.io/king/" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2204.13683.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Hanselmann2022ECCV_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://youtu.be/8-7sRLjxsY0" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Hanselmann2022ECCV_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/king" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseHanselmann2022ECCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseHanselmann2022ECCV"><div class="card card-body"><pre><code>@inproceedings{Hanselmann2022ECCV, 
	author = {Niklas Hanselmann and Katrin Renz and Kashyap Chitta and Apratim Bhattacharyya and Andreas Geiger}, 
	title = {KING: Generating Safety-Critical Driving Scenarios for Robust Imitation via Kinematics Gradients}, 
	booktitle = {European Conference on Computer Vision (ECCV)}, 
	year = {2022}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Chitta2021ITS.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/1905.12737" target="_blank">Training Data Subset Search with Ensemble Active Learning</a> <br><span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://alvarezlopezjosem.github.io/" target="_blank">Jose Alvarez</a>, <a href="https://scholar.google.com/citations?user=HzaEH_MAAAAJ&hl=en" target="_blank">Elmar Haussmann</a>, <a href="http://www.clement.farabet.net/" target="_blank">Clement Farabet</a> <br><span style="font-style: italic;">Transactions on Intelligent Transportation Systems (T-ITS)</span>, 2021 <br><a href="https://arxiv.org/abs/1905.12737" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/1905.12737.pdf" target="_blank">Paper</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseChitta2021ITS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseChitta2021ITS"><div class="card card-body"><pre><code>@article{Chitta2021ITS, 
	author = {Kashyap Chitta and Jose Alvarez and Elmar Haussmann and Clement Farabet}, 
	title = {Training Data Subset Search with Ensemble Active Learning}, 
	booktitle = {Transactions on Intelligent Transportation Systems (T-ITS)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Sauer2021NEURIPS.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://sites.google.com/view/projected-gan/" target="_blank">Projected GANs Converge Faster</a> <br><a href="https://axelsauer.com/" target="_blank">Axel Sauer</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://scholar.google.com/citations?user=ayN8HoQAAAAJ&hl=en" target="_blank">Jens Muller</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Advances in Neural Information Processing Systems (NeurIPS)</span>, 2021 <br><a href="https://sites.google.com/view/projected-gan/" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2111.01007.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Sauer2021NEURIPS_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://slideslive.com/38968099/projected-gans-converge-faster?ref=speaker-58293" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Sauer2021NEURIPS_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/projected_gan" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseSauer2021NEURIPS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseSauer2021NEURIPS"><div class="card card-body"><pre><code>@inproceedings{Sauer2021NEURIPS, 
	author = {Axel Sauer and Kashyap Chitta and Jens Muller and Andreas Geiger}, 
	title = {Projected GANs Converge Faster}, 
	booktitle = {Advances in Neural Information Processing Systems (NeurIPS)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Weis2021JMLR.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2006.07034" target="_blank">Benchmarking Unsupervised Object Representations for Video Sequences</a> <br><a href="https://scholar.google.com/citations?user=fxJ_ZOQAAAAJ&hl=en" target="_blank">Marissa Weis</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.yash-sharma.com/" target="_blank">Yash Sharma</a>, <a href="https://robustml.is.mpg.de/person/wbrendel" target="_blank">Wieland Brendel</a>, <a href="http://bethgelab.org/people/matthias/" target="_blank">Matthias Bethge</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a>, <a href="https://eckerlab.org/" target="_blank">Alexander Ecker</a> <br><span style="font-style: italic;">Journal of Machine Learning Research (JMLR)</span>, 2021 <br><a href="https://arxiv.org/abs/2006.07034" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2006.07034.pdf" target="_blank">Paper</a> / <a href="https://www.youtube.com/watch?v=CHI40_AdsuM" target="_blank">Video</a> / <a href="https://github.com/ecker-lab/object-centric-representation-benchmark" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseWeis2021JMLR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseWeis2021JMLR"><div class="card card-body"><pre><code>@article{Weis2021JMLR, 
	author = {Marissa Weis and Kashyap Chitta and Yash Sharma and Wieland Brendel and Matthias Bethge and Andreas Geiger and Alexander Ecker}, 
	title = {Benchmarking Unsupervised Object Representations for Video Sequences}, 
	booktitle = {Journal of Machine Learning Research (JMLR)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Chitta2021ICCV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2109.04456" target="_blank">NEAT: Neural Attention Fields for End-to-End Autonomous Driving</a> <span style="color: red;">(Runner Up, 2020 CARLA Challenge)</span><br><span style="font-weight: bold";>Kashyap Chitta</span>*, <a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>*, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">International Conference on Computer Vision (ICCV)</span>, 2021 <br><a href="https://arxiv.org/abs/2109.04456" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2109.04456.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Chitta2021ICCV_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://youtu.be/S72yji4hsiU" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Chitta2021ICCV_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/neat" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseChitta2021ICCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseChitta2021ICCV"><div class="card card-body"><pre><code>@inproceedings{Chitta2021ICCV, 
	author = {Kashyap Chitta and Aditya Prakash and Andreas Geiger}, 
	title = {NEAT: Neural Attention Fields for End-to-End Autonomous Driving}, 
	booktitle = {International Conference on Computer Vision (ICCV)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="background-color: #ffffd0; margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Prakash2021CVPR.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://ap229997.github.io/projects/transfuser/" target="_blank">Multi-Modal Fusion Transformer for End-to-End Autonomous Driving</a> <br><a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>*, <span style="font-weight: bold";>Kashyap Chitta</span>*, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2021 <br><a href="https://ap229997.github.io/projects/transfuser/" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2104.09224.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Prakash2021CVPR_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://www.youtube.com/watch?v=WxadQyQ2gMs" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Prakash2021CVPR_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/transfuser/tree/cvpr2021" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsePrakash2021CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsePrakash2021CVPR"><div class="card card-body"><pre><code>@inproceedings{Prakash2021CVPR, 
	author = {Aditya Prakash and Kashyap Chitta and Andreas Geiger}, 
	title = {Multi-Modal Fusion Transformer for End-to-End Autonomous Driving}, 
	booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Behl2020IROS.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2005.10091" target="_blank">Label Efficient Visual Abstractions for Autonomous Driving</a> <br><a href="https://aseembehl.github.io/" target="_blank">Aseem Behl</a>*, <span style="font-weight: bold";>Kashyap Chitta</span>*, <a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>, <a href="https://eshed1.github.io/" target="_blank">Eshed Ohn-Bar</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">International Conference on Intelligent Robots and Systems (IROS)</span>, 2020 <br><a href="https://arxiv.org/abs/2005.10091" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2005.10091.pdf" target="_blank">Paper</a> / <a href="https://www.youtube.com/watch?v=5SszfDWrqzo" target="_blank">Video</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseBehl2020IROS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseBehl2020IROS"><div class="card card-body"><pre><code>@inproceedings{Behl2020IROS, 
	author = {Aseem Behl and Kashyap Chitta and Aditya Prakash and Eshed Ohn-Bar and Andreas Geiger}, 
	title = {Label Efficient Visual Abstractions for Autonomous Driving}, 
	booktitle = {International Conference on Intelligent Robots and Systems (IROS)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Haussmann2020IV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2004.04699" target="_blank">Scalable Active Learning for Object Detection</a> <br><a href="https://scholar.google.com/citations?user=HzaEH_MAAAAJ&hl=en" target="_blank">Elmar Haussmann</a>, <a href="https://scholar.google.com/citations?hl=en&user=x3xLe8wAAAAJ" target="_blank">Michele Fenzi</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.linkedin.com/in/jan-ivanecky-226b31116" target="_blank">Jan Ivanecky</a>, <a href="https://ieeexplore.ieee.org/author/37088650397" target="_blank">Hanson Xu</a>, <a href="https://scholar.google.com/citations?user=Pvt-cf0AAAAJ&hl=en" target="_blank">Donna Roy</a>, <a href="https://scholar.google.com/citations?user=OQOmmooAAAAJ&hl=en" target="_blank">Akshita Mittel</a>, <a href="https://www.linkedin.com/in/nicolaskoumchatzky" target="_blank">Nicolas Koumchatzky</a>, <a href="http://www.clement.farabet.net/" target="_blank">Clement Farabet</a>, <a href="https://alvarezlopezjosem.github.io/" target="_blank">Jose Alvarez</a> <br><span style="font-style: italic;">Intelligent Vehicles Symposium (IV)</span>, 2020 <br><a href="https://arxiv.org/abs/2004.04699" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2004.04699.pdf" target="_blank">Paper</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseHaussmann2020IV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseHaussmann2020IV"><div class="card card-body"><pre><code>@inproceedings{Haussmann2020IV, 
	author = {Elmar Haussmann and Michele Fenzi and Kashyap Chitta and Jan Ivanecky and Hanson Xu and Donna Roy and Akshita Mittel and Nicolas Koumchatzky and Clement Farabet and Jose Alvarez}, 
	title = {Scalable Active Learning for Object Detection}, 
	booktitle = {Intelligent Vehicles Symposium (IV)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Prakash2020CVPR.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Prakash_Exploring_Data_Aggregation_in_Policy_Learning_for_Vision-Based_Urban_Autonomous_CVPR_2020_paper.html" target="_blank">Exploring Data Aggregation in Policy Learning for Vision-Based Urban Autonomous Driving</a> <br><a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>, <a href="https://aseembehl.github.io/" target="_blank">Aseem Behl</a>, <a href="https://eshed1.github.io/" target="_blank">Eshed Ohn-Bar</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2020 <br><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Prakash_Exploring_Data_Aggregation_in_Policy_Learning_for_Vision-Based_Urban_Autonomous_CVPR_2020_paper.html" target="_blank">Abs</a> / <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Prakash_Exploring_Data_Aggregation_in_Policy_Learning_for_Vision-Based_Urban_Autonomous_CVPR_2020_paper.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Prakash2020CVPR_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://www.youtube.com/watch?v=VxYUM5VTnAI" target="_blank">Video</a> / <a href="https://github.com/autonomousvision/data_aggregation" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsePrakash2020CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsePrakash2020CVPR"><div class="card card-body"><pre><code>@inproceedings{Prakash2020CVPR, 
	author = {Aditya Prakash and Aseem Behl and Eshed Ohn-Bar and Kashyap Chitta and Andreas Geiger}, 
	title = {Exploring Data Aggregation in Policy Learning for Vision-Based Urban Autonomous Driving}, 
	booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="background-color: #ffffd0; margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Ohn-bar2020CVPR.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Ohn-Bar_Learning_Situational_Driving_CVPR_2020_paper.html" target="_blank">Learning Situational Driving</a> <br><a href="https://eshed1.github.io/" target="_blank">Eshed Ohn-Bar</a>, <a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>, <a href="https://aseembehl.github.io/" target="_blank">Aseem Behl</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2020 <br><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Ohn-Bar_Learning_Situational_Driving_CVPR_2020_paper.html" target="_blank">Abs</a> / <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Ohn-Bar_Learning_Situational_Driving_CVPR_2020_paper.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Ohn-Bar2020CVPR_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://www.youtube.com/watch?v=XkZyEqO1l5o" target="_blank">Video</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseOhn-bar2020CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseOhn-bar2020CVPR"><div class="card card-body"><pre><code>@inproceedings{Ohn-bar2020CVPR, 
	author = {Eshed Ohn-Bar and Aditya Prakash and Aseem Behl and Kashyap Chitta and Andreas Geiger}, 
	title = {Learning Situational Driving}, 
	booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Chitta2020WACV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/1907.11821" target="_blank">Quadtree Generating Networks: Efficient Hierarchical Scene Parsing with Sparse Convolutions</a> <br><span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://alvarezlopezjosem.github.io/" target="_blank">Jose Alvarez</a>, <a href="http://www.cs.cmu.edu/~hebert/" target="_blank">Martial Hebert</a> <br><span style="font-style: italic;">Winter Conference on Applications of Computer Vision (WACV)</span>, 2020 <br><a href="https://arxiv.org/abs/1907.11821" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/1907.11821.pdf" target="_blank">Paper</a> / <a href="assets/pdf/posters/Chitta2020WACV.pdf" target="_blank">Poster</a> / <a href="https://github.com/kashyap7x/QGN" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseChitta2020WACV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseChitta2020WACV"><div class="card card-body"><pre><code>@inproceedings{Chitta2020WACV, 
	author = {Kashyap Chitta and Jose Alvarez and Martial Hebert}, 
	title = {Quadtree Generating Networks: Efficient Hierarchical Scene Parsing with Sparse Convolutions}, 
	booktitle = {Winter Conference on Applications of Computer Vision (WACV)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div>
            </div>
        </div>
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="">
                <h4>Selected Talks</h4>
                <hr>
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/Chitta2024ECCV.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Specializing General-Purpose Video Diffusion Models<br><span style="font-style: italic;">ECCV Tutorial: Recent Advances in Video Content Understanding and Generation, Milan</span>, 2024 <br><a href="assets/pdf/talks/Chitta2024ECCV.pdf" target="_blank">Slides</a> / <a href="https://youtu.be/2BGxnJLD_qw?si=8wdoSZFyY4l1B22B" target="_blank">Recording</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/Chitta2024CVPRb.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Non-Reactive Autonomous Vehicle Simulation and Benchmarking<br><span style="font-style: italic;">CVPR Workshop on Autonomous Driving, Seattle</span>, 2024 <br><a href="assets/pdf/talks/Chitta2024CVPRb.pdf" target="_blank">Slides</a> / <a href="https://youtu.be/Qe76HRmPDe0?si=hwCnJRiwLtqrJJ70" target="_blank">Recording</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/Chitta2024CVPRa.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Synthesizing Simulation Environments with Generative Models<br><span style="font-style: italic;">CVPR Workshop on Data-Driven Autonomous Driving Simulation, Seattle</span>, 2024 <br><a href="assets/pdf/talks/Chitta2024CVPRa.pdf" target="_blank">Slides</a> / <a href="https://youtu.be/YGxcg2WmkWo?si=-r_6yObHs7H9xJEn&t=28483" target="_blank">Recording</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/Chitta2023Sogang.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Reading, Writing, and Reviewing for Robotics and Computer Vision Research<br><span style="font-style: italic;">Sogang University Applied Data Engineering Seminar (Virtual)</span>, 2023 <br><a href="assets/pdf/talks/Chitta2023Sogang.pdf" target="_blank">Slides</a> / <a href="https://youtu.be/joOkBbH5cLs" target="_blank">Recording</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/Chitta2023ICRA.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">End-to-End Driving with Attention<br><span style="font-style: italic;">ICRA Workshop on Scalable Autonomous Driving, London</span>, 2023 <br><a href="assets/pdf/talks/Chitta2023ICRA.pdf" target="_blank">Slides</a> / <a href="https://youtu.be/pAsSJffXw4E" target="_blank">Recording</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/Chitta2022AIR.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Imitation with Transformer-Based Sensor Fusion for Autonomous Driving<br><span style="font-style: italic;">University of Toronto AI in Robotics Seminar (Virtual)</span>, 2022 <br><a href="assets/pdf/talks/Chitta2022AIR.pdf" target="_blank">Slides</a> / <a href="https://www.youtube.com/watch?v=-GMhYcxOiEU" target="_blank">Recording</a> </div> </div> </div>
            </div>
        </div>
        <div class="row" style="margin-top: 3em; margin-bottom: 1em;">
            
            <div class="col-sm-12" style="">
                <p>
                    This website is based on the lightweight and easy-to-use template from Michael Niemeyer. <a href="https://github.com/m-niemeyer/m-niemeyer.github.io" target="_blank">Check out his github repository for instructions on how to use it!</a>
                </p>
            </div>
    
        </div>
    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
      integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
      crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
      integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
      crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
      integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
      crossorigin="anonymous"></script>
</body>

</html>
    