
    <!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  <title>Kashyap Chitta | AI Researcher</title>
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
</head>

<body>
    <div class="container">
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="margin-bottom: 1em;">
            <h3 class="display-4" style="text-align: center;"><span style="font-weight: bold;">Kashyap</span> Chitta</h3>
            </div>
            <br>
            <div class="col-md-8" style="">
                
                <p>
                    I am a PhD student at the University of Tübingen, Germany, where I am part of the <a href = "https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/autonomous-vision/home/" target="_blank">Autonomous Vision Group</a> led by <a href = "http://www.cvlibs.net" target="_blank">Prof. Andreas Geiger</a>.
                </p>
                <p>
                    <span style="font-weight: bold;">News:</span>
                    I was selected for the <a href="https://iccv2023.thecvf.com/doctoral.consortium-353000-2-30.php" target="_blank">doctoral consortium</a> at ICCV 2023, as a 2023 <a href="https://sites.google.com/view/rsspioneers2023/participants" target="_blank">RSS pioneer</a>, and a top reviewer for <a href="https://cvpr2023.thecvf.com/Conferences/2023/OutstandingReviewers" target="_blank">CVPR</a>, <a href="https://twitter.com/kashyap7x/status/1712169445349560517" target="_blank">ICCV</a>, and <a href="https://neurips.cc/Conferences/2023/ProgramCommittee#top-reivewers" target="_blank">NeurIPS</a> 2023. Our team also won the <a href="https://opendrivelab.com/AD23Challenge.html#nuplan_planning" target="_blank">2023 nuPlan challenge</a>!
                </p>
                <p>
                    <span style="font-weight: bold;">Workshops:</span>
                    I am co organizing the <a href = "https://opendrivelab.com/cvpr2024/workshop/" target="_blank">CVPR 2024 Workshop on Foundation Models for Autonomous Systems</a> and <a href = "https://sites.google.com/view/rsspioneers2024/" target="_blank">RSS 2024 Pioneers Workshop</a>. We have exciting speaker lineups and panel discussions planned for both. The CVPR workshop will host the 2024 edition of the <a href = "https://opendrivelab.com/cvpr2024/challenge/" target="_blank">Autonomous Systems Challenge</a> with several new tracks. Stay tuned for more details!
                </p>
                <p>
                    <span style="font-weight: bold;">Research:</span>
                    I am excited about data-driven solutions to complex decision-making tasks. Currently, my research focuses on self-driving vehicles. Specifically, I am interested in vehicle motion planning from either sensor inputs (e.g., CARLA) or abstract state inputs (e.g., nuPlan). Further, I am big fan of simulation, and am interested in building data-driven simulators tailored towards improving the robustness and generalization of learned policies. Representative papers are <span style="background-color:#ffffd0">highlighted</span> below.
                </p>
                <p>
                    <span style="font-weight: bold;">Bio:</span>
                    Kashyap did a bachelor's degree in electronics at the <a href="https://www.rvce.edu.in/" target="_blank">RV College of Engineering</a>, India. He then moved to the US in 2017 to obtain his Master's degree in computer vision from <a href="https://www.ri.cmu.edu/" target="_blank">Carnegie Mellon University</a>, where he was advised by <a href = "http://www.cs.cmu.edu/~hebert/" target="_blank">Prof. Martial Hebert</a>. During this time, he was also an intern at NVIDIA working with <a href = "https://alvarezlopezjosem.github.io/" target="_blank">Dr. Jose M. Alvarez</a>. He is currently a PhD student in the <a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/autonomous-vision/home/" target="_blank">Autonomous Vision Group</a> at the University of Tübingen, Germany, supervised by <a href="http://cvlibs.net/" target="_blank">Prof. Andreas Geiger</a>.
                </p>
                <p>
                    <a href="https://kashyap7x.github.io/assets/pdf/kchitta_cv.pdf" target="_blank" style="margin-right: 15px"><i class="fa fa-address-card fa-lg"></i> CV</a>
                    <a href="mailto:kashyap.chitta@uni-tuebingen.de" style="margin-right: 15px"><i class="far fa-envelope-open fa-lg"></i> Mail</a>
                    <a href="https://scholar.google.com/citations?user=vX5i2CcAAAAJ&hl=en" target="_blank" style="margin-right: 15px"><i class="fa-solid fa-graduation-cap"></i> Scholar</a>
                    <a href="https://twitter.com/kashyap7x" target="_blank" style="margin-right: 15px"><i class="fab fa-twitter fa-lg"></i> X</a>
                    <a href="https://www.linkedin.com/in/kchitta" target="_blank" style="margin-right: 15px"><i class="fab fa-linkedin fa-lg"></i> Linkedin</a>
                    <a href="https://www.facebook.com/kashyap7x" target="_blank" style="margin-right: 15px"><i class="fab fa-facebook fa-lg"></i> Facebook</a>
                    <a href="https://github.com/kashyap7x" target="_blank" style="margin-right: 15px"><i class="fab fa-github fa-lg"></i> GitHub</a>
                    <a href="https://www.youtube.com/channel/UC_rpEkxE-pUAV8v0wjdtg5w" target="_blank" style="margin-right: 15px"><i class="fab fa-youtube fa-lg"></i> YouTube</a>
                </p>
    
            </div>
            <div class="col-md-4" style="">
                <img src="assets/img/profile.jpg" class="img-thumbnail" alt="Profile picture">
            </div>
        </div>
        <div class="row" style="margin-top: 1em;">
            <div class="col-sm-12" style="">
                <h4>Publications</h4>
                <hr>
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Dauner2023CORL.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2306.07962" target="_blank">Parting with Misconceptions about Learning-based Vehicle Motion Planning</a> <span style="color: red;">(Winner, 2023 nuPlan Challenge)</span><br><a href="https://danieldauner.github.io/" target="_blank">Daniel Dauner</a>, <a href="https://mh0797.github.io/" target="_blank">Marcel Hallgarten</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a>, <span style="font-weight: bold";>Kashyap Chitta</span> <br><span style="font-style: italic;">Conference on Robot Learning (CoRL)</span>, 2023 <br><a href="https://arxiv.org/abs/2306.07962" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2306.07962.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Dauner2023CORL_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://www.youtube.com/watch?v=oIOYQAR5P4w" target="_blank">Video</a> / <a href="assets/pdf/posters/Dauner2023CORL.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/tuplan_garage" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseDauner2023CORL" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseDauner2023CORL"><div class="card card-body"><pre><code>@inproceedings{Dauner2023CORL, 
	author = {Daniel Dauner and Marcel Hallgarten and Andreas Geiger and Kashyap Chitta}, 
	title = {Parting with Misconceptions about Learning-based Vehicle Motion Planning}, 
	booktitle = {Conference on Robot Learning (CoRL)}, 
	year = {2023}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Jaeger2023ICCV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2306.07957" target="_blank">Hidden Biases of End-to-End Driving Models</a> <span style="color: red;">(Winner, 2022 CARLA Challenge Map Track)</span><br><a href="https://kait0.github.io/" target="_blank">Bernhard Jaeger</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">International Conference on Computer Vision (ICCV)</span>, 2023 <br><a href="https://arxiv.org/abs/2306.07957" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2306.07957.pdf" target="_blank">Paper</a> / <a href="https://youtu.be/XbWmGwggcuQ" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Jaeger2023ICCV_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/carla_garage" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseJaeger2023ICCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseJaeger2023ICCV"><div class="card card-body"><pre><code>@inproceedings{Jaeger2023ICCV, 
	author = {Bernhard Jaeger and Kashyap Chitta and Andreas Geiger}, 
	title = {Hidden Biases of End-to-End Driving Models}, 
	booktitle = {International Conference on Computer Vision (ICCV)}, 
	year = {2023}, 
}</pre></code></div></div> </div> </div> </div><div style="background-color: #ffffd0; margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Chitta2023PAMI.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2205.15997" target="_blank">TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving</a> <span style="color: red;">(Runner Up, 2021 CARLA Challenge)</span><br><span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>, <a href="https://kait0.github.io/" target="_blank">Bernhard Jaeger</a>, <a href="https://niujinshuchong.github.io/" target="_blank">Zehao Yu</a>, <a href="https://www.katrinrenz.de/" target="_blank">Katrin Renz</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</span>, 2023 <br><a href="https://arxiv.org/abs/2205.15997" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2205.15997.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Chitta2022PAMI_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://www.youtube.com/watch?v=-GMhYcxOiEU" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Chitta2022PAMI_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/transfuser" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseChitta2023PAMI" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseChitta2023PAMI"><div class="card card-body"><pre><code>@article{Chitta2023PAMI, 
	author = {Kashyap Chitta and Aditya Prakash and Bernhard Jaeger and Zehao Yu and Katrin Renz and Andreas Geiger}, 
	title = {TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving}, 
	booktitle = {Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)}, 
	year = {2023}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Renz2022CORL.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://www.katrinrenz.de/plant/" target="_blank">PlanT: Explainable Planning Transformers via Object-Level Representations</a> <br><a href="https://www.katrinrenz.de/" target="_blank">Katrin Renz</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://merceaotniel.github.io/" target="_blank">Otniel-Bogdan Mercea</a>, <a href="https://www.eml-unitue.de/people/almut-sophia-koepke" target="_blank">Sophia Koepke</a>, <a href="https://www.eml-unitue.de/people/zeynep-akata" target="_blank">Zeynep Akata</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Conference on Robot Learning (CoRL)</span>, 2022 <br><a href="https://www.katrinrenz.de/plant/" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2210.14222.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Renz2022CORL_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://youtu.be/sbnbrLKO9c8" target="_blank">Video</a> / <a href="assets/pdf/posters/Renz2022CORL.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/plant" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseRenz2022CORL" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseRenz2022CORL"><div class="card card-body"><pre><code>@inproceedings{Renz2022CORL, 
	author = {Katrin Renz and Kashyap Chitta and Otniel-Bogdan Mercea and Sophia Koepke and Zeynep Akata and Andreas Geiger}, 
	title = {PlanT: Explainable Planning Transformers via Object-Level Representations}, 
	booktitle = {Conference on Robot Learning (CoRL)}, 
	year = {2022}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Hanselmann2022ECCV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://lasnik.github.io/king/" target="_blank">KING: Generating Safety-Critical Driving Scenarios for Robust Imitation via Kinematics Gradients</a> <span style="color: red;">(Oral)</span><br><a href="https://lasnik.github.io/" target="_blank">Niklas Hanselmann</a>, <a href="https://www.katrinrenz.de/" target="_blank">Katrin Renz</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://apratimbhattacharyya18.github.io/" target="_blank">Apratim Bhattacharyya</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">European Conference on Computer Vision (ECCV)</span>, 2022 <br><a href="https://lasnik.github.io/king/" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2204.13683.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Hanselmann2022ECCV_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://youtu.be/8-7sRLjxsY0" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Hanselmann2022ECCV_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/king" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseHanselmann2022ECCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseHanselmann2022ECCV"><div class="card card-body"><pre><code>@inproceedings{Hanselmann2022ECCV, 
	author = {Niklas Hanselmann and Katrin Renz and Kashyap Chitta and Apratim Bhattacharyya and Andreas Geiger}, 
	title = {KING: Generating Safety-Critical Driving Scenarios for Robust Imitation via Kinematics Gradients}, 
	booktitle = {European Conference on Computer Vision (ECCV)}, 
	year = {2022}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Chitta2021ITS.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/1905.12737" target="_blank">Training Data Subset Search with Ensemble Active Learning</a> <br><span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://alvarezlopezjosem.github.io/" target="_blank">Jose Alvarez</a>, <a href="https://scholar.google.com/citations?user=HzaEH_MAAAAJ&hl=en" target="_blank">Elmar Haussmann</a>, <a href="http://www.clement.farabet.net/" target="_blank">Clement Farabet</a> <br><span style="font-style: italic;">Transactions on Intelligent Transportation Systems (T-ITS)</span>, 2021 <br><a href="https://arxiv.org/abs/1905.12737" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/1905.12737.pdf" target="_blank">Paper</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseChitta2021ITS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseChitta2021ITS"><div class="card card-body"><pre><code>@article{Chitta2021ITS, 
	author = {Kashyap Chitta and Jose Alvarez and Elmar Haussmann and Clement Farabet}, 
	title = {Training Data Subset Search with Ensemble Active Learning}, 
	booktitle = {Transactions on Intelligent Transportation Systems (T-ITS)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Sauer2021NEURIPS.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://sites.google.com/view/projected-gan/" target="_blank">Projected GANs Converge Faster</a> <br><a href="https://axelsauer.com/" target="_blank">Axel Sauer</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://scholar.google.com/citations?user=ayN8HoQAAAAJ&hl=en" target="_blank">Jens Muller</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Advances in Neural Information Processing Systems (NeurIPS)</span>, 2021 <br><a href="https://sites.google.com/view/projected-gan/" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2111.01007.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Sauer2021NEURIPS_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://slideslive.com/38968099/projected-gans-converge-faster?ref=speaker-58293" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Sauer2021NEURIPS_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/projected_gan" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseSauer2021NEURIPS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseSauer2021NEURIPS"><div class="card card-body"><pre><code>@inproceedings{Sauer2021NEURIPS, 
	author = {Axel Sauer and Kashyap Chitta and Jens Muller and Andreas Geiger}, 
	title = {Projected GANs Converge Faster}, 
	booktitle = {Advances in Neural Information Processing Systems (NeurIPS)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Weis2021JMLR.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2006.07034" target="_blank">Benchmarking Unsupervised Object Representations for Video Sequences</a> <br><a href="https://scholar.google.com/citations?user=fxJ_ZOQAAAAJ&hl=en" target="_blank">Marissa Weis</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.yash-sharma.com/" target="_blank">Yash Sharma</a>, <a href="https://robustml.is.mpg.de/person/wbrendel" target="_blank">Wieland Brendel</a>, <a href="http://bethgelab.org/people/matthias/" target="_blank">Matthias Bethge</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a>, <a href="https://eckerlab.org/" target="_blank">Alexander Ecker</a> <br><span style="font-style: italic;">Journal of Machine Learning Research (JMLR)</span>, 2021 <br><a href="https://arxiv.org/abs/2006.07034" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2006.07034.pdf" target="_blank">Paper</a> / <a href="https://www.youtube.com/watch?v=CHI40_AdsuM" target="_blank">Video</a> / <a href="https://github.com/ecker-lab/object-centric-representation-benchmark" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseWeis2021JMLR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseWeis2021JMLR"><div class="card card-body"><pre><code>@article{Weis2021JMLR, 
	author = {Marissa Weis and Kashyap Chitta and Yash Sharma and Wieland Brendel and Matthias Bethge and Andreas Geiger and Alexander Ecker}, 
	title = {Benchmarking Unsupervised Object Representations for Video Sequences}, 
	booktitle = {Journal of Machine Learning Research (JMLR)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="background-color: #ffffd0; margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Chitta2021ICCV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2109.04456" target="_blank">NEAT: Neural Attention Fields for End-to-End Autonomous Driving</a> <span style="color: red;">(Runner Up, 2020 CARLA Challenge)</span><br><span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">International Conference on Computer Vision (ICCV)</span>, 2021 <br><a href="https://arxiv.org/abs/2109.04456" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2109.04456.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Chitta2021ICCV_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://youtu.be/S72yji4hsiU" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Chitta2021ICCV_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/neat" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseChitta2021ICCV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseChitta2021ICCV"><div class="card card-body"><pre><code>@inproceedings{Chitta2021ICCV, 
	author = {Kashyap Chitta and Aditya Prakash and Andreas Geiger}, 
	title = {NEAT: Neural Attention Fields for End-to-End Autonomous Driving}, 
	booktitle = {International Conference on Computer Vision (ICCV)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Prakash2021CVPR.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://ap229997.github.io/projects/transfuser/" target="_blank">Multi-Modal Fusion Transformer for End-to-End Autonomous Driving</a> <br><a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2021 <br><a href="https://ap229997.github.io/projects/transfuser/" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2104.09224.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Prakash2021CVPR_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://www.youtube.com/watch?v=WxadQyQ2gMs" target="_blank">Video</a> / <a href="https://www.cvlibs.net/publications/Prakash2021CVPR_poster.pdf" target="_blank">Poster</a> / <a href="https://github.com/autonomousvision/transfuser/tree/cvpr2021" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsePrakash2021CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsePrakash2021CVPR"><div class="card card-body"><pre><code>@inproceedings{Prakash2021CVPR, 
	author = {Aditya Prakash and Kashyap Chitta and Andreas Geiger}, 
	title = {Multi-Modal Fusion Transformer for End-to-End Autonomous Driving}, 
	booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)}, 
	year = {2021}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Behl2020IROS.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2005.10091" target="_blank">Label Efficient Visual Abstractions for Autonomous Driving</a> <br><a href="https://aseembehl.github.io/" target="_blank">Aseem Behl</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>, <a href="https://eshed1.github.io/" target="_blank">Eshed Ohn-Bar</a>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">International Conference on Intelligent Robots and Systems (IROS)</span>, 2020 <br><a href="https://arxiv.org/abs/2005.10091" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2005.10091.pdf" target="_blank">Paper</a> / <a href="https://www.youtube.com/watch?v=5SszfDWrqzo" target="_blank">Video</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseBehl2020IROS" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseBehl2020IROS"><div class="card card-body"><pre><code>@inproceedings{Behl2020IROS, 
	author = {Aseem Behl and Kashyap Chitta and Aditya Prakash and Eshed Ohn-Bar and Andreas Geiger}, 
	title = {Label Efficient Visual Abstractions for Autonomous Driving}, 
	booktitle = {International Conference on Intelligent Robots and Systems (IROS)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Haussmann2020IV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/2004.04699" target="_blank">Scalable Active Learning for Object Detection</a> <br><a href="https://scholar.google.com/citations?user=HzaEH_MAAAAJ&hl=en" target="_blank">Elmar Haussmann</a>, <a href="https://scholar.google.com/citations?hl=en&user=x3xLe8wAAAAJ" target="_blank">Michele Fenzi</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.linkedin.com/in/jan-ivanecky-226b31116" target="_blank">Jan Ivanecky</a>, <a href="https://ieeexplore.ieee.org/author/37088650397" target="_blank">Hanson Xu</a>, <a href="https://scholar.google.com/citations?user=Pvt-cf0AAAAJ&hl=en" target="_blank">Donna Roy</a>, <a href="https://scholar.google.com/citations?user=OQOmmooAAAAJ&hl=en" target="_blank">Akshita Mittel</a>, <a href="https://www.linkedin.com/in/nicolaskoumchatzky" target="_blank">Nicolas Koumchatzky</a>, <a href="http://www.clement.farabet.net/" target="_blank">Clement Farabet</a>, <a href="https://alvarezlopezjosem.github.io/" target="_blank">Jose Alvarez</a> <br><span style="font-style: italic;">Intelligent Vehicles Symposium (IV)</span>, 2020 <br><a href="https://arxiv.org/abs/2004.04699" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/2004.04699.pdf" target="_blank">Paper</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseHaussmann2020IV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseHaussmann2020IV"><div class="card card-body"><pre><code>@inproceedings{Haussmann2020IV, 
	author = {Elmar Haussmann and Michele Fenzi and Kashyap Chitta and Jan Ivanecky and Hanson Xu and Donna Roy and Akshita Mittel and Nicolas Koumchatzky and Clement Farabet and Jose Alvarez}, 
	title = {Scalable Active Learning for Object Detection}, 
	booktitle = {Intelligent Vehicles Symposium (IV)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Ohn-bar2020CVPR.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Ohn-Bar_Learning_Situational_Driving_CVPR_2020_paper.html" target="_blank">Learning Situational Driving</a> <br><a href="https://eshed1.github.io/" target="_blank">Eshed Ohn-Bar</a>, <a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>, <a href="https://aseembehl.github.io/" target="_blank">Aseem Behl</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2020 <br><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Ohn-Bar_Learning_Situational_Driving_CVPR_2020_paper.html" target="_blank">Abs</a> / <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Ohn-Bar_Learning_Situational_Driving_CVPR_2020_paper.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Ohn-Bar2020CVPR_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://www.youtube.com/watch?v=XkZyEqO1l5o" target="_blank">Video</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseOhn-bar2020CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseOhn-bar2020CVPR"><div class="card card-body"><pre><code>@inproceedings{Ohn-bar2020CVPR, 
	author = {Eshed Ohn-Bar and Aditya Prakash and Aseem Behl and Kashyap Chitta and Andreas Geiger}, 
	title = {Learning Situational Driving}, 
	booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Prakash2020CVPR.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Prakash_Exploring_Data_Aggregation_in_Policy_Learning_for_Vision-Based_Urban_Autonomous_CVPR_2020_paper.html" target="_blank">Exploring Data Aggregation in Policy Learning for Vision-Based Urban Autonomous Driving</a> <br><a href="https://ap229997.github.io/" target="_blank">Aditya Prakash</a>, <a href="https://aseembehl.github.io/" target="_blank">Aseem Behl</a>, <a href="https://eshed1.github.io/" target="_blank">Eshed Ohn-Bar</a>, <span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://www.cvlibs.net/" target="_blank">Andreas Geiger</a> <br><span style="font-style: italic;">Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2020 <br><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Prakash_Exploring_Data_Aggregation_in_Policy_Learning_for_Vision-Based_Urban_Autonomous_CVPR_2020_paper.html" target="_blank">Abs</a> / <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Prakash_Exploring_Data_Aggregation_in_Policy_Learning_for_Vision-Based_Urban_Autonomous_CVPR_2020_paper.pdf" target="_blank">Paper</a> / <a href="https://www.cvlibs.net/publications/Prakash2020CVPR_supplementary.pdf" target="_blank">Supplementary</a> / <a href="https://www.youtube.com/watch?v=VxYUM5VTnAI" target="_blank">Video</a> / <a href="https://github.com/autonomousvision/data_aggregation" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsePrakash2020CVPR" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapsePrakash2020CVPR"><div class="card card-body"><pre><code>@inproceedings{Prakash2020CVPR, 
	author = {Aditya Prakash and Aseem Behl and Eshed Ohn-Bar and Kashyap Chitta and Andreas Geiger}, 
	title = {Exploring Data Aggregation in Policy Learning for Vision-Based Urban Autonomous Driving}, 
	booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/publications/Chitta2020WACV.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9"><a href="https://arxiv.org/abs/1907.11821" target="_blank">Quadtree Generating Networks: Efficient Hierarchical Scene Parsing with Sparse Convolutions</a> <br><span style="font-weight: bold";>Kashyap Chitta</span>, <a href="https://alvarezlopezjosem.github.io/" target="_blank">Jose Alvarez</a>, <a href="http://www.cs.cmu.edu/~hebert/" target="_blank">Martial Hebert</a> <br><span style="font-style: italic;">Winter Conference on Applications of Computer Vision (WACV)</span>, 2020 <br><a href="https://arxiv.org/abs/1907.11821" target="_blank">Abs</a> / <a href="https://arxiv.org/pdf/1907.11821.pdf" target="_blank">Paper</a> / <a href="assets/pdf/posters/Chitta2020WACV.pdf" target="_blank">Poster</a> / <a href="https://github.com/kashyap7x/QGN" target="_blank">Code</a> /<button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapseChitta2020WACV" aria-expanded="false" aria-controls="collapseExample" style="margin-left: -6px; margin-top: -2px;">Bibtex</button><div class="collapse" id="collapseChitta2020WACV"><div class="card card-body"><pre><code>@inproceedings{Chitta2020WACV, 
	author = {Kashyap Chitta and Jose Alvarez and Martial Hebert}, 
	title = {Quadtree Generating Networks: Efficient Hierarchical Scene Parsing with Sparse Convolutions}, 
	booktitle = {Winter Conference on Applications of Computer Vision (WACV)}, 
	year = {2020}, 
}</pre></code></div></div> </div> </div> </div>
            </div>
        </div>
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="">
                <h4>Talks</h4>
                <hr>
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/Chitta2023Sogang.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Reading, Writing, and Reviewing for Robotics and Computer Vision Research<br><span style="font-style: italic;">Sogang University Applied Data Engineering Seminar (Virtual)</span>, 2023 <br><a href="assets/pdf/talks/Chitta2023Sogang.pdf" target="_blank">Slides</a> / <a href="https://youtu.be/joOkBbH5cLs" target="_blank">Recording</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/Chitta2023ICRA.jpeg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">End-to-End Driving with Attention<br><span style="font-style: italic;">ICRA Workshop on Scalable Autonomous Driving, London</span>, 2023 <br><a href="assets/pdf/talks/Chitta2023ICRA.pdf" target="_blank">Slides</a> / <a href="https://youtu.be/pAsSJffXw4E" target="_blank">Recording</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/Chitta2023ETH.jpg" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Imitation via Abstraction and Planning<br><span style="font-style: italic;">ETH Computer Vision Lab, Zürich</span>, 2023 <br><a href="assets/pdf/talks/Chitta2023ETH.pdf" target="_blank">Slides</a> / <a href="https://www.youtube.com/watch?v=Z2mi7YdC4Hk" target="_blank">Recording</a> </div> </div> </div><div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-3"><img src="assets/img/talks/Chitta2022AIR.png" class="img-fluid img-thumbnail" alt="Project image"></div><div class="col-sm-9">Imitation with Transformer-Based Sensor Fusion for Autonomous Driving<br><span style="font-style: italic;">University of Toronto AI in Robotics Seminar (Virtual)</span>, 2022 <br><a href="assets/pdf/talks/Chitta2022AIR.pdf" target="_blank">Slides</a> / <a href="https://www.youtube.com/watch?v=-GMhYcxOiEU" target="_blank">Recording</a> </div> </div> </div>
            </div>
        </div>
        <div class="row" style="margin-top: 3em; margin-bottom: 1em;">
            
            <div class="col-sm-12" style="">
                <p>
                    This website is based on the lightweight and easy-to-use template from Michael Niemeyer. <a href="https://github.com/m-niemeyer/m-niemeyer.github.io" target="_blank">Check out his github repository for instructions on how to use it!</a>
                </p>
            </div>
    
        </div>
    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
      integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
      crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
      integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
      crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
      integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
      crossorigin="anonymous"></script>
</body>

</html>
    